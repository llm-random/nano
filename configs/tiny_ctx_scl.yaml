defaults:
  - _cluster@_here_: local
  - _model@_here_: tiny
  - _trainer@_here_: context_scaling
  - _dataset@_here_: local_dummy
  - _checkpoints@_here_: none
  - _misc@_here_: default
  - _eval@_here_: none
  - _self_

common:
  sequence_length: 16
  batch_size: 2

trainer:
  gradient_accumulation_steps: 1
  n_steps: 100
  learning_rate: 1e-3
  eval_interval: 10
  eval_long_ctx_interval: 20

  eval_long_ctx_dataloader:
    dataset_path: data_long_ctx
    num_workers: 1
    total_batch_size: 32
    tokenize_fn: 
      _target_: src.core.datasets.gpt2_tokenize_fn

infrastructure:
  metric_logger:
    name: tiny_Local
    tags:
      - nano
      - local
      - tiny
      - context_scaling