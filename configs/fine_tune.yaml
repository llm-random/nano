# TODO contains lr scheduler bug

defaults:
  - _cluster@_here_: entropy_4
  - _model@_here_: llama_3_1_50
  - _trainer@_here_: llama
  - _dataset@_here_: c4
  - _checkpoints@_here_: none
  - _misc@_here_: default

infrastructure:
  metric_logger:
    name: test
    tags:
      - nano
      - pc
      - fine-tune

trainer:
  n_steps: 2000
  learning_rate: 6.103515625e-05
  gradient_accumulation_steps: 4

  checkpoint:
   load:
    path: null # change me
