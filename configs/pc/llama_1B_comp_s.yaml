defaults:
  # - ../_cluster@_here_: helios #helios
  - ../_cluster@_here_: entropy
  - ../_model/llama@_here_: projected_1B
  - ../_trainer@_here_: llama
  - ../_dataset@_here_: c4
  - ../_checkpoints@_here_: none
  - ../_misc@_here_: default


common:
  n_blocks: 4
  sequence_length: 1024
  # sequence_length: asd
  # sequence_length: asd
  # sequence_length: asd
  # sequence_length: asd
  ^sequence_length: 
    # - 8
    - 16
    # - 32
    - 64
    # - 128
    - 256
    # - 512
    - 1024
  # sequence_length: 16
  # sequence_length: 8
  batch_size: 512
  ^batch_size: 
    # - asd
    # - asd
    - 262144
    - 131072
    - 65536
    - 32768
    - 16384
    - 12288
    - 8192
    - 4096
    - 2048
    - 1024
    - 512
    - 256
    - 128
    - 64
    - 32
    - 16

  # dmodel: 448 # 10
  # dff: 1728
  # dmodel: 960 # 30
  # dff: 3840
  dmodel: 1344 # 50
  dff: 5376
  # dmodel: 1728 # 75
  # dff: 6912
  target_dmodel: ${common.dmodel}
  target_dff: ${common.dff}

  # ^smart_init: 
  #   - svd
  #   - mpp
  #   - False
  


trainer:
  gradient_accumulation_steps: 1
  ^n_steps: 
    - 201

  learning_rate: 13

  scheduler:
    warmup_steps: 40

infrastructure:
  metric_logger:
    name: Llame_PC
    tags:
      - nano
      - pc
      - llama_1
      - projected_compression
      # - 10p
      # - 30p
      - 50p
      - TEST
      - REBUTAL
      - speedup
  
  slurm: 
    job-name: ${infrastructure.metric_logger.name}
    gres: gpu:4
    time: "0-0:20:00"
    # time: "0-3:00:00"
    # time: "0-8:00:00"
    # time: "0-24:00:00"

apply_functions:
  - _target_: src.projected_compression.compression.init_compression
    _partial_: true
    dimensions_importances_path: /storage_nvme_3/mstefaniak/pc/fw_importances_8m/minitron_dimensions_importances.pt # entropy ACTIVATIONS llama31
    # dimensions_importances_path: /net/scratch/hscra/plgrid/plgmstefaniak/checkpoints/llama_1_fw_importances/minitron_dimensions_importances.pt # #helios ACTIVATIONS llama31
    target_dmodel: ${common.dmodel}
    target_dff: ${common.dff}
    smart_init: ${common.smart_init}
