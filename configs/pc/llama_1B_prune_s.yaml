defaults:
  # - ../_cluster@_here_: helios #helios
  - ../_cluster@_here_: entropy
  - ../_model@_here_: llama_3_1
  - ../_trainer@_here_: llama
  - ../_dataset@_here_: c4
  - ../_checkpoints@_here_: none
  - ../_misc@_here_: default


common:
  # sequence_length: 1024
  sequence_length: 16
  batch_size: 512
  ^batch_size: 
    - 16384
    - 12288
    - 8192
    - 4096
    - 2048
    - 1024
    # - 512
    # - 256
    # - 128
    # - 64
    # - 32
    # - 16

  target_dmodel: 448 # 10
  target_dff: 1728
  # target_dmodel: 960 # 30
  # target_dff: 3840
  # target_dmodel: 1344 #50
  # target_dff: 5376
  # target_dmodel: 1728 # 75
  # target_dff: 6912


trainer:
  gradient_accumulation_steps: 1
  ^n_steps: 
    - 201

  learning_rate: 12 #optimal fo 10%

  scheduler:
    warmup_steps: 40

infrastructure:
  metric_logger:
    name: Llame_HP
    tags:
      - nano
      - pc
      - llama_1
      - hard_pruning
      - 10p
      # - 30p
      # - 50p
      - TEST
      - REBUTAL
      - speedup
  
  slurm:
    job-name: ${infrastructure.metric_logger.name}
    gres: gpu:4
    time: "0-0:20:00"
 
apply_functions:
  - _target_: src.projected_compression.pruning.prune
    _partial_: true
    
    dimensions_importances_path: /storage_nvme_3/mstefaniak/pc/fw_importances_8m/minitron_dimensions_importances.pt # entropy ACTIVATIONS llama31
    # dimensions_importances_path: /net/scratch/hscra/plgrid/plgmstefaniak/checkpoints/llama_1_fw_importances/minitron_dimensions_importances.pt # #helios ACTIVATIONS llama31

    target_dmodel: ${common.target_dmodel}
    target_dff: ${common.target_dff}

