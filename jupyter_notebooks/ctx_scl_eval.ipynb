{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c895ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from hydra import initialize_config_dir, compose\n",
    "from hydra.utils import instantiate\n",
    "import resolver as _\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
    "import torch.distributed.checkpoint as dcp\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.distributed.checkpoint.stateful import Stateful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5d49f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ torch.distributed initialized (1 GPU)\n"
     ]
    }
   ],
   "source": [
    "# --- env vars for torch.distributed ---\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "dist.init_process_group(\n",
    "    backend=\"nccl\",\n",
    "    rank=0,\n",
    "    world_size=1,\n",
    ")\n",
    "\n",
    "print(\"✅ torch.distributed initialized (1 GPU)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874fbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- paths ---\n",
    "CKPT_DIR = \"/storage_nvme_4/nano/models/from_helios/mqa_dff3520/step_320000\"\n",
    "DATASET_DIR = \"/storage_nvme_1/llm-random/datasets/c4/long_context_2048n8192\"\n",
    "OUT_CSV = \"MQA_3520_loss_k16_42B.csv\"\n",
    "SEQ_LEN = 2048   # set to 8192 if you want hard truncation to context size\n",
    "BATCH_SIZE = 32\n",
    "exp_config_name = \"ctx_scl_k16_long_mqa\"    # remember to pick grid variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3afffffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instantiated on cuda:0\n",
      "Parameters: 311,628,800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:430: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config_dir = str(Path.cwd() / \"configs\")\n",
    "\n",
    "with initialize_config_dir(config_dir=config_dir, version_base=None):\n",
    "    cfg = compose(config_name=exp_config_name)\n",
    "\n",
    "model = instantiate(cfg.model, _convert_=\"all\").to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model instantiated on {device}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "fsdp_model = FSDP(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5046f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:763: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.\n",
      "  warnings.warn(\n",
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:701: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded for inference (optimizer skipped)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:817: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.\n",
      "  warnings.warn(\n",
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:854: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class ModelOnly(Stateful):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {\"model\": self.model.state_dict()}\n",
    "\n",
    "    def load_state_dict(self, sd):\n",
    "        self.model.load_state_dict(sd[\"model\"], strict=True)\n",
    "\n",
    "state = {\"app\": ModelOnly(fsdp_model)}\n",
    "dcp.load(state, checkpoint_id=CKPT_DIR)\n",
    "\n",
    "fsdp_model.eval()\n",
    "print(\"✅ Model loaded for inference (optimizer skipped)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae109e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'timestamp', 'url', 'length'],\n",
      "    num_rows: 8192\n",
      "})\n",
      "Columns: ['text', 'timestamp', 'url', 'length']\n",
      "Example keys: dict_keys(['text', 'timestamp', 'url', 'length'])\n",
      "Text preview: Welcome to Boston Mamas Rock! – where we’re giving a voice to fabulous local mamas from all walks of life. Read on for today’s interview with Susan Dorson & Amy Weitzman, two local moms on a mission t...\n"
     ]
    }
   ],
   "source": [
    "ds = load_from_disk(DATASET_DIR)\n",
    "\n",
    "print(ds)\n",
    "print(\"Columns:\", ds.column_names)\n",
    "print(\"Example keys:\", ds[0].keys())\n",
    "print(\"Text preview:\", (ds[0][\"text\"][:200] + \"...\") if \"text\" in ds[0] else \"NO 'text' COLUMN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afd3bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 50257\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\n",
    "\n",
    "print(\"Tokenizer vocab size:\", len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72985f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_no_pad(batch):\n",
    "    texts = [ex[\"text\"] for ex in batch]\n",
    "    urls = [ex[\"url\"] for ex in batch]\n",
    "    timestamps = [ex[\"timestamp\"] for ex in batch]\n",
    "\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        add_special_tokens=False,\n",
    "        truncation=True,\n",
    "        max_length=SEQ_LEN,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    input_ids = enc[\"input_ids\"]  # [B, <=SEQ_LEN]\n",
    "\n",
    "    # keep only samples that actually reached SEQ_LEN\n",
    "    keep = input_ids.size(1) == SEQ_LEN\n",
    "    if not keep:\n",
    "        return None  # drop this batch\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"url\": urls,\n",
    "        \"timestamp\": timestamps,\n",
    "    }\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@torch.no_grad()\n",
    "def batch_per_token_losses(model, input_ids):\n",
    "    input_ids = input_ids.to(device)        # [B, T]\n",
    "\n",
    "    out = model(input_ids)\n",
    "    logits = out.logits if hasattr(out, \"logits\") else out  # [B, T, V]\n",
    "\n",
    "    logits = logits[:, :-1, :]   # [B, T-1, V]\n",
    "    targets = input_ids[:, 1:]   # [B, T-1]\n",
    "\n",
    "    losses = F.cross_entropy(\n",
    "        logits.reshape(-1, logits.size(-1)),\n",
    "        targets.reshape(-1),\n",
    "        reduction=\"none\",\n",
    "    ).reshape(targets.shape)     # [B, T-1]\n",
    "\n",
    "    return losses.cpu(), targets.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e40ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655c90093c934c398bc3e587a66010d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader = DataLoader(\n",
    "    ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_no_pad,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "for batch in tqdm(loader):\n",
    "    if batch is None:\n",
    "        continue\n",
    "\n",
    "    losses, targets = batch_per_token_losses(model, batch[\"input_ids\"])\n",
    "    all_losses.append(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41423db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def tensors_rows_to_csv(tensors, path=\"tensors.csv\"):\n",
    "    rows = []\n",
    "    for t in tensors:\n",
    "        rows.append(t.detach().cpu())\n",
    "    stacked = torch.cat(rows, dim=0)   # (num_tensors * N, N)\n",
    "    pd.DataFrame(stacked.numpy()).to_csv(path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28f61588",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_rows_to_csv(all_losses, path=OUT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5901d88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2037</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.380030</td>\n",
       "      <td>8.621256</td>\n",
       "      <td>6.870979</td>\n",
       "      <td>7.890626</td>\n",
       "      <td>8.752855</td>\n",
       "      <td>1.675966</td>\n",
       "      <td>7.656805</td>\n",
       "      <td>4.865206</td>\n",
       "      <td>2.138330</td>\n",
       "      <td>3.451378</td>\n",
       "      <td>...</td>\n",
       "      <td>2.176812</td>\n",
       "      <td>7.168613</td>\n",
       "      <td>4.727401</td>\n",
       "      <td>3.990843</td>\n",
       "      <td>1.318014</td>\n",
       "      <td>1.044751</td>\n",
       "      <td>2.883807</td>\n",
       "      <td>5.411947</td>\n",
       "      <td>4.330785</td>\n",
       "      <td>1.583291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.219949</td>\n",
       "      <td>7.931793</td>\n",
       "      <td>9.692278</td>\n",
       "      <td>2.566181</td>\n",
       "      <td>5.394570</td>\n",
       "      <td>5.408353</td>\n",
       "      <td>0.116439</td>\n",
       "      <td>4.205744</td>\n",
       "      <td>6.292889</td>\n",
       "      <td>3.137556</td>\n",
       "      <td>...</td>\n",
       "      <td>5.322657</td>\n",
       "      <td>2.968103</td>\n",
       "      <td>2.034466</td>\n",
       "      <td>2.765616</td>\n",
       "      <td>3.947982</td>\n",
       "      <td>3.603583</td>\n",
       "      <td>8.287707</td>\n",
       "      <td>0.894379</td>\n",
       "      <td>1.263876</td>\n",
       "      <td>1.332970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.066014</td>\n",
       "      <td>6.690225</td>\n",
       "      <td>2.764734</td>\n",
       "      <td>3.897488</td>\n",
       "      <td>4.028049</td>\n",
       "      <td>5.534327</td>\n",
       "      <td>1.602152</td>\n",
       "      <td>6.999635</td>\n",
       "      <td>4.307511</td>\n",
       "      <td>10.394428</td>\n",
       "      <td>...</td>\n",
       "      <td>3.829848</td>\n",
       "      <td>0.104630</td>\n",
       "      <td>0.028694</td>\n",
       "      <td>2.512537</td>\n",
       "      <td>3.888413</td>\n",
       "      <td>0.497884</td>\n",
       "      <td>6.186173</td>\n",
       "      <td>0.112987</td>\n",
       "      <td>11.303635</td>\n",
       "      <td>4.428379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.484951</td>\n",
       "      <td>0.065470</td>\n",
       "      <td>5.952685</td>\n",
       "      <td>9.535594</td>\n",
       "      <td>8.614286</td>\n",
       "      <td>7.266953</td>\n",
       "      <td>0.302838</td>\n",
       "      <td>2.081389</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>0.015402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>1.034212</td>\n",
       "      <td>0.010907</td>\n",
       "      <td>1.349706</td>\n",
       "      <td>0.044986</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.006391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.171163</td>\n",
       "      <td>13.471144</td>\n",
       "      <td>3.424521</td>\n",
       "      <td>8.452765</td>\n",
       "      <td>6.609230</td>\n",
       "      <td>3.802885</td>\n",
       "      <td>5.457229</td>\n",
       "      <td>13.996242</td>\n",
       "      <td>4.587484</td>\n",
       "      <td>4.963999</td>\n",
       "      <td>...</td>\n",
       "      <td>4.449986</td>\n",
       "      <td>2.700965</td>\n",
       "      <td>0.352735</td>\n",
       "      <td>0.698385</td>\n",
       "      <td>4.651100</td>\n",
       "      <td>9.894043</td>\n",
       "      <td>10.196079</td>\n",
       "      <td>0.055088</td>\n",
       "      <td>4.668685</td>\n",
       "      <td>2.494915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2047 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1         2         3         4         5         6  \\\n",
       "0   0.380030   8.621256  6.870979  7.890626  8.752855  1.675966  7.656805   \n",
       "1  10.219949   7.931793  9.692278  2.566181  5.394570  5.408353  0.116439   \n",
       "2   1.066014   6.690225  2.764734  3.897488  4.028049  5.534327  1.602152   \n",
       "3   3.484951   0.065470  5.952685  9.535594  8.614286  7.266953  0.302838   \n",
       "4   3.171163  13.471144  3.424521  8.452765  6.609230  3.802885  5.457229   \n",
       "\n",
       "           7         8          9  ...      2037      2038      2039  \\\n",
       "0   4.865206  2.138330   3.451378  ...  2.176812  7.168613  4.727401   \n",
       "1   4.205744  6.292889   3.137556  ...  5.322657  2.968103  2.034466   \n",
       "2   6.999635  4.307511  10.394428  ...  3.829848  0.104630  0.028694   \n",
       "3   2.081389  0.015525   0.015402  ...  0.000632  1.034212  0.010907   \n",
       "4  13.996242  4.587484   4.963999  ...  4.449986  2.700965  0.352735   \n",
       "\n",
       "       2040      2041      2042       2043      2044       2045      2046  \n",
       "0  3.990843  1.318014  1.044751   2.883807  5.411947   4.330785  1.583291  \n",
       "1  2.765616  3.947982  3.603583   8.287707  0.894379   1.263876  1.332970  \n",
       "2  2.512537  3.888413  0.497884   6.186173  0.112987  11.303635  4.428379  \n",
       "3  1.349706  0.044986  0.014288   0.000107  0.001127   0.002771  0.006391  \n",
       "4  0.698385  4.651100  9.894043  10.196079  0.055088   4.668685  2.494915  \n",
       "\n",
       "[5 rows x 2047 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(OUT_CSV)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703c2359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
