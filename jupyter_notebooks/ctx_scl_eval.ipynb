{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c895ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from hydra import initialize_config_dir, compose\n",
    "from hydra.utils import instantiate\n",
    "import resolver as _\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
    "import torch.distributed.checkpoint as dcp\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.core.checkpointing import TrainingState\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5d49f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ torch.distributed initialized (1 GPU)\n"
     ]
    }
   ],
   "source": [
    "# --- env vars for torch.distributed ---\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "dist.init_process_group(\n",
    "    backend=\"nccl\",\n",
    "    rank=0,\n",
    "    world_size=1,\n",
    ")\n",
    "\n",
    "print(\"✅ torch.distributed initialized (1 GPU)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874fbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- paths ---\n",
    "CKPT_DIR = \"/storage_nvme_4/nano/models/112902/0/step_100\"\n",
    "DATASET_DIR = \"/storage_nvme_1/llm-random/datasets/c4/long_context_2048n8192\"\n",
    "OUT_CSV = \"per_token_loss.csv\"\n",
    "SEQ_LEN = 512   # set to 8192 if you want hard truncation to context size\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3afffffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instantiated on cuda:0\n",
      "Parameters: 295,900,160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:430: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config_dir = str(Path.cwd() / \"configs\")\n",
    "\n",
    "with initialize_config_dir(config_dir=config_dir, version_base=None):\n",
    "    cfg = compose(config_name=\"tiny_remote_ctx_scl\")\n",
    "\n",
    "model = instantiate(cfg.model, _convert_=\"all\").to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model instantiated on {device}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "fsdp_model = FSDP(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5046f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:763: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.\n",
      "  warnings.warn(\n",
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:701: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.\n",
      "  warnings.warn(\n",
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:859: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. \n",
      "  warnings.warn(\n",
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/checkpoint/planner_helpers.py:406: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  device = getattr(value, \"device\", None)\n",
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:463: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  and md.size != obj.size()\n",
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:40: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  dim_0_size = sharded_tensor.size()[0]  # type: ignore[index]\n",
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:41: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  tensor_numel = sharded_tensor.size().numel()  # type: ignore[union-attr]\n",
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:65: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  tensor = tensor.narrow(0, 0, tensor_numel).reshape(sharded_tensor.size())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sharded checkpoint loaded via TrainingState\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:817: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.\n",
      "  warnings.warn(\n",
      "/storage_nvme_4/nano/pixi/.pixi/envs/default/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:854: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(fsdp_model.parameters(), lr=0.0)\n",
    "scheduler = instantiate(cfg.trainer.scheduler)(\n",
    "    optimizer=optimizer, n_steps=cfg.trainer.n_steps\n",
    ")\n",
    "state = {\"app\": TrainingState(fsdp_model, optimizer, scheduler)}\n",
    "\n",
    "dcp.load(\n",
    "    state,\n",
    "    checkpoint_id=CKPT_DIR,\n",
    ")\n",
    "\n",
    "print(\"✅ Sharded checkpoint loaded via TrainingState\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae109e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'timestamp', 'url', 'length'],\n",
      "    num_rows: 8192\n",
      "})\n",
      "Columns: ['text', 'timestamp', 'url', 'length']\n",
      "Example keys: dict_keys(['text', 'timestamp', 'url', 'length'])\n",
      "Text preview: Welcome to Boston Mamas Rock! – where we’re giving a voice to fabulous local mamas from all walks of life. Read on for today’s interview with Susan Dorson & Amy Weitzman, two local moms on a mission t...\n"
     ]
    }
   ],
   "source": [
    "ds = load_from_disk(DATASET_DIR)\n",
    "\n",
    "print(ds)\n",
    "print(\"Columns:\", ds.column_names)\n",
    "print(\"Example keys:\", ds[0].keys())\n",
    "print(\"Text preview:\", (ds[0][\"text\"][:200] + \"...\") if \"text\" in ds[0] else \"NO 'text' COLUMN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afd3bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 50257\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\n",
    "\n",
    "print(\"Tokenizer vocab size:\", len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72985f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_no_pad(batch):\n",
    "    texts = [ex[\"text\"] for ex in batch]\n",
    "    urls = [ex[\"url\"] for ex in batch]\n",
    "    timestamps = [ex[\"timestamp\"] for ex in batch]\n",
    "\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        add_special_tokens=False,\n",
    "        truncation=True,\n",
    "        max_length=SEQ_LEN,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    input_ids = enc[\"input_ids\"]  # [B, <=SEQ_LEN]\n",
    "\n",
    "    # keep only samples that actually reached SEQ_LEN\n",
    "    keep = input_ids.size(1) == SEQ_LEN\n",
    "    if not keep:\n",
    "        return None  # drop this batch\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"url\": urls,\n",
    "        \"timestamp\": timestamps,\n",
    "    }\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@torch.no_grad()\n",
    "def batch_per_token_losses(model, input_ids):\n",
    "    input_ids = input_ids.to(device)        # [B, T]\n",
    "\n",
    "    out = model(input_ids)\n",
    "    logits = out.logits if hasattr(out, \"logits\") else out  # [B, T, V]\n",
    "\n",
    "    logits = logits[:, :-1, :]   # [B, T-1, V]\n",
    "    targets = input_ids[:, 1:]   # [B, T-1]\n",
    "\n",
    "    losses = F.cross_entropy(\n",
    "        logits.reshape(-1, logits.size(-1)),\n",
    "        targets.reshape(-1),\n",
    "        reduction=\"none\",\n",
    "    ).reshape(targets.shape)     # [B, T-1]\n",
    "\n",
    "    return losses.cpu(), targets.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e40ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a6c52f075e4ee0be0661876c0a5814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader = DataLoader(\n",
    "    ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_no_pad,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "with open(OUT_CSV, \"w\") as f:\n",
    "    f.write(\"sample_idx,token_pos,token_id,loss,url,timestamp\\n\")\n",
    "\n",
    "    sample_idx = 0\n",
    "    for batch in tqdm(loader):\n",
    "        if batch is None:\n",
    "            continue\n",
    "\n",
    "        losses, targets = batch_per_token_losses(model, batch[\"input_ids\"])\n",
    "        all_losses.append(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41423db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def tensors_rows_to_csv(tensors, path=\"tensors.csv\"):\n",
    "    rows = []\n",
    "    for t in tensors:\n",
    "        rows.append(t.detach().cpu())\n",
    "    stacked = torch.cat(rows, dim=0)   # (num_tensors * N, N)\n",
    "    pd.DataFrame(stacked.numpy()).to_csv(path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28f61588",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_rows_to_csv(all_losses, path=\"per_token_loss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5901d88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.085172</td>\n",
       "      <td>9.934204</td>\n",
       "      <td>8.996014</td>\n",
       "      <td>11.504110</td>\n",
       "      <td>9.986458</td>\n",
       "      <td>5.382188</td>\n",
       "      <td>8.986745</td>\n",
       "      <td>7.447004</td>\n",
       "      <td>7.199303</td>\n",
       "      <td>4.985841</td>\n",
       "      <td>...</td>\n",
       "      <td>7.789421</td>\n",
       "      <td>5.581819</td>\n",
       "      <td>8.445265</td>\n",
       "      <td>3.161999</td>\n",
       "      <td>8.101936</td>\n",
       "      <td>2.602781</td>\n",
       "      <td>5.626294</td>\n",
       "      <td>8.515235</td>\n",
       "      <td>11.292056</td>\n",
       "      <td>7.314084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.822108</td>\n",
       "      <td>9.538289</td>\n",
       "      <td>11.703181</td>\n",
       "      <td>2.757541</td>\n",
       "      <td>6.331216</td>\n",
       "      <td>6.654324</td>\n",
       "      <td>3.294222</td>\n",
       "      <td>9.728536</td>\n",
       "      <td>5.596427</td>\n",
       "      <td>7.050842</td>\n",
       "      <td>...</td>\n",
       "      <td>5.177627</td>\n",
       "      <td>8.263029</td>\n",
       "      <td>4.265507</td>\n",
       "      <td>5.648528</td>\n",
       "      <td>8.326301</td>\n",
       "      <td>3.465414</td>\n",
       "      <td>1.184136</td>\n",
       "      <td>9.803685</td>\n",
       "      <td>10.910895</td>\n",
       "      <td>8.787147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.437046</td>\n",
       "      <td>4.038119</td>\n",
       "      <td>7.277862</td>\n",
       "      <td>6.908977</td>\n",
       "      <td>7.173857</td>\n",
       "      <td>9.113975</td>\n",
       "      <td>4.560616</td>\n",
       "      <td>8.288863</td>\n",
       "      <td>3.227307</td>\n",
       "      <td>11.024434</td>\n",
       "      <td>...</td>\n",
       "      <td>8.091841</td>\n",
       "      <td>10.495870</td>\n",
       "      <td>4.027703</td>\n",
       "      <td>11.385570</td>\n",
       "      <td>8.660601</td>\n",
       "      <td>6.807249</td>\n",
       "      <td>3.459799</td>\n",
       "      <td>4.571454</td>\n",
       "      <td>7.038602</td>\n",
       "      <td>2.673347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.886657</td>\n",
       "      <td>3.729474</td>\n",
       "      <td>8.190474</td>\n",
       "      <td>9.948400</td>\n",
       "      <td>9.285893</td>\n",
       "      <td>11.868690</td>\n",
       "      <td>10.385446</td>\n",
       "      <td>5.357697</td>\n",
       "      <td>10.134768</td>\n",
       "      <td>3.330999</td>\n",
       "      <td>...</td>\n",
       "      <td>11.794025</td>\n",
       "      <td>7.370442</td>\n",
       "      <td>10.625010</td>\n",
       "      <td>11.624344</td>\n",
       "      <td>9.877463</td>\n",
       "      <td>12.368013</td>\n",
       "      <td>4.121586</td>\n",
       "      <td>4.333259</td>\n",
       "      <td>7.558920</td>\n",
       "      <td>7.106237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.346539</td>\n",
       "      <td>13.069561</td>\n",
       "      <td>12.154629</td>\n",
       "      <td>11.288257</td>\n",
       "      <td>7.264080</td>\n",
       "      <td>4.670476</td>\n",
       "      <td>4.505062</td>\n",
       "      <td>10.830602</td>\n",
       "      <td>10.596910</td>\n",
       "      <td>4.051549</td>\n",
       "      <td>...</td>\n",
       "      <td>9.952202</td>\n",
       "      <td>9.714775</td>\n",
       "      <td>2.942371</td>\n",
       "      <td>10.537815</td>\n",
       "      <td>3.000067</td>\n",
       "      <td>13.041159</td>\n",
       "      <td>10.456656</td>\n",
       "      <td>6.487325</td>\n",
       "      <td>2.987190</td>\n",
       "      <td>9.749381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3         4          5          6  \\\n",
       "0   4.085172   9.934204   8.996014  11.504110  9.986458   5.382188   8.986745   \n",
       "1  10.822108   9.538289  11.703181   2.757541  6.331216   6.654324   3.294222   \n",
       "2   3.437046   4.038119   7.277862   6.908977  7.173857   9.113975   4.560616   \n",
       "3   9.886657   3.729474   8.190474   9.948400  9.285893  11.868690  10.385446   \n",
       "4   7.346539  13.069561  12.154629  11.288257  7.264080   4.670476   4.505062   \n",
       "\n",
       "           7          8          9  ...        501        502        503  \\\n",
       "0   7.447004   7.199303   4.985841  ...   7.789421   5.581819   8.445265   \n",
       "1   9.728536   5.596427   7.050842  ...   5.177627   8.263029   4.265507   \n",
       "2   8.288863   3.227307  11.024434  ...   8.091841  10.495870   4.027703   \n",
       "3   5.357697  10.134768   3.330999  ...  11.794025   7.370442  10.625010   \n",
       "4  10.830602  10.596910   4.051549  ...   9.952202   9.714775   2.942371   \n",
       "\n",
       "         504       505        506        507       508        509       510  \n",
       "0   3.161999  8.101936   2.602781   5.626294  8.515235  11.292056  7.314084  \n",
       "1   5.648528  8.326301   3.465414   1.184136  9.803685  10.910895  8.787147  \n",
       "2  11.385570  8.660601   6.807249   3.459799  4.571454   7.038602  2.673347  \n",
       "3  11.624344  9.877463  12.368013   4.121586  4.333259   7.558920  7.106237  \n",
       "4  10.537815  3.000067  13.041159  10.456656  6.487325   2.987190  9.749381  \n",
       "\n",
       "[5 rows x 511 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"per_token_loss.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703c2359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
